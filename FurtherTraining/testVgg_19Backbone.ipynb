{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8edb9-7fa5-42d1-a076-7a5655aec03a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras \n",
    "\n",
    "from keras.utils import normalize\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "#Resizing images, if needed\n",
    "SIZE_X = 128 \n",
    "SIZE_Y = 128\n",
    "n_classes=4 #Number of classes for segmentation\n",
    "\n",
    "#Capture training image info as a list\n",
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(\"../data/patches_128_useful/patch_img/\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        print(img_path, sep = ' ')\n",
    "        img = cv2.imread(img_path, 1)       \n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        train_images.append(img)\n",
    "       \n",
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)\n",
    "print(train_images.shape)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "train_masks = [] \n",
    "\n",
    "for directory_path in glob.glob(\"../data/patches_128_useful/patch_mask/\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.tif\")):\n",
    "        print(mask_path, sep = ' ')\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
    "        train_masks.append(mask)\n",
    "        \n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)\n",
    "print(train_masks.shape)\n",
    "\n",
    "#Encode labels... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1,1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_encoded_original_shape)\n",
    "\n",
    "#train_images = np.expand_dims(train_images, axis=3)\n",
    "#train_images = normalize(train_images, axis=1)\n",
    "\n",
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)\n",
    "\n",
    "#Create a subset of data for quick testing\n",
    "#Picking 10% for testing and remaining for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
    "# #Further split training data t a smaller subset for quick testing of models\n",
    "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "#Full Data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n",
    "\n",
    "# Add print statements to check tensor shapes\n",
    "print(\"Input shapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train_cat shape:\", y_train_cat.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test_cat shape:\", y_test_cat.shape)\n",
    "\n",
    "\n",
    "###Model 3\n",
    "BACKBONE3 = 'vgg19'\n",
    "preprocess_input3 = sm.get_preprocessing(BACKBONE3)\n",
    "\n",
    "# preprocess input\n",
    "X_train3 = preprocess_input3(X_train)\n",
    "X_test3 = preprocess_input3(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad048c8-0179-4b14-aa81-7d167613881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "### FOR NOW LET US FOCUS ON A SINGLE MODEL\n",
    "\n",
    "#Set compile=False as we are not loading it for training, only for prediction.\n",
    "# model1 = load_model('../SavedModels/res34_backbone_200epochs.hdf5', compile=False)\n",
    "model3 = load_model('../Segmentation_Models/vgg19/CheckPoints/weights-improvement_vgg19.hdf5', compile=False)\n",
    "\n",
    "# plot graph\n",
    "#IOU\n",
    "y_pred3=model3.predict(X_test3)\n",
    "y_pred3_argmax=np.argmax(y_pred3, axis=3)\n",
    "\n",
    "\n",
    "#Using built in keras function\n",
    "#from keras.metrics import MeanIoU\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred3_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728752d2-322e-42ea-a520-7ca885cdfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate I0U for each class...\n",
    "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "print(values)\n",
    "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "print(\"IoU for class1 is: \", class1_IoU)\n",
    "print(\"IoU for class2 is: \", class2_IoU)\n",
    "print(\"IoU for class3 is: \", class3_IoU)\n",
    "print(\"IoU for class4 is: \", class4_IoU)\n",
    "\n",
    "#Verify the prediction on first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fcb10-81eb-4a50-b0b9-3aa9fa2f01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0, :,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8f397-4cbc-4e98-8a78-77920b4eb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_masks[0], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c7cea-240c-4d3e-aaa3-c34cdf83a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with a larger size\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Assuming train_masks contains at least 16 mask images\n",
    "for i in range(16):\n",
    "    ax = fig.add_subplot(4, 4, i + 1)  # Create a 4x4 grid of subplots\n",
    "    ax.imshow(train_masks[i+48], cmap='gray') #16 patches make a single image\n",
    "    ax.set_title(f\"Patch {i + 1}\")  # Add a title for each subplot\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "plt.show()  # Display all 16 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c45fe4-3a4b-47f4-b494-b1bfa3814784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test some random images\n",
    "for j in range(30):\n",
    "    import random\n",
    "    test_img_number = random.randint(0, len(X_test3)-1)\n",
    "    test_img = X_test3[test_img_number]\n",
    "    ground_truth=y_test[test_img_number]\n",
    "    test_img_input=np.expand_dims(test_img, 0)\n",
    "    \n",
    "    test_img_input3 = preprocess_input3(test_img_input)\n",
    "    \n",
    "    test_pred3 = model3.predict(test_img_input3)\n",
    "    test_prediction3 = np.argmax(test_pred3, axis=3)[0,:,:]\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "    plt.subplot(232)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "    plt.subplot(233)\n",
    "    plt.title('Prediction on test image')\n",
    "    plt.imshow(test_prediction3, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d40a5-4576-484b-ba82-19e64b7846a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/Vooban/Smoothly-Blend-Image-Patches\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models as sm\n",
    "\n",
    "from smooth_tiled_predictions import predict_img_with_smooth_windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec24232-0436-4003-b327-de0bf294c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from keras.models import load_model\n",
    "# Set your backbone, preprocess_input, patch_size, and n_classes here\n",
    "BACKBONE = 'vgg19'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "# size of patches\n",
    "patch_size = 128\n",
    "\n",
    "# Number of classes \n",
    "n_classes = 4\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = \"../LargeImages/Original\"\n",
    "mask_directory = \"../LargeImages/Mask\"\n",
    "\n",
    "# Define the result directory\n",
    "result_directory_mask = f'segmentation_results/{BACKBONE}/mask/'\n",
    "result_directory_segmented = f'segmentation_results/{BACKBONE}/segmented/'\n",
    "os.makedirs(result_directory_mask, exist_ok=True)\n",
    "os.makedirs(result_directory_segmented, exist_ok=True)\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [file for file in os.listdir(image_directory) if file.endswith(\".jpg\")]\n",
    "\n",
    "# Load the model\n",
    "model = load_model(f'../Segmentation_Models/{BACKBONE}/CheckPoints/weights-improvement_{BACKBONE}.hdf5', compile=False)\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    img = cv2.imread(os.path.join(image_directory, image_file))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input_img = preprocess_input(img)\n",
    "\n",
    "    # Load the corresponding mask\n",
    "    mask_file = os.path.splitext(image_file)[0] + \".tif\"\n",
    "    original_mask = cv2.imread(os.path.join(mask_directory, mask_file))\n",
    "    # original_mask = cv2.cvtColor(original_mask, cv2.COLOR_BGR2RGB)\n",
    "    original_mask = original_mask[:, :, 0]\n",
    "\n",
    "    # Predict using smooth blending\n",
    "    predictions_smooth = predict_img_with_smooth_windowing(\n",
    "        input_img,\n",
    "        window_size=patch_size,\n",
    "        subdivisions=2,\n",
    "        nb_classes=n_classes,\n",
    "        pred_func=(\n",
    "            lambda img_batch_subdiv: model.predict((img_batch_subdiv))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_prediction = np.argmax(predictions_smooth, axis=2).astype(np.uint8)\n",
    "\n",
    "    # Save the final prediction and original mask\n",
    "    result_image_file = f'{result_directory_segmented}{os.path.splitext(image_file)[0]}_segmented_{BACKBONE}.tif'\n",
    "    result_mask_file = f'{result_directory_mask}{os.path.splitext(image_file)[0]}_mask_{BACKBONE}.tif'\n",
    "    print(result_image_file)\n",
    "    print(result_mask_file)\n",
    "    tiff.imwrite(result_image_file, final_prediction)\n",
    "    tiff.imwrite(result_mask_file, original_mask)\n",
    "    # Display the images if needed\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(221)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(222)\n",
    "    plt.title('Testing Label')\n",
    "    plt.imshow(original_mask, cmap = 'gray')\n",
    "    plt.subplot(223)\n",
    "    plt.title('Prediction with smooth blending')\n",
    "    plt.imshow(final_prediction, cmap= 'gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df638917-d2ad-4f03-8b24-e7578226bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tifffile as tiff\n",
    "# Set your backbone, preprocess_input, patch_size, and n_classes here\n",
    "BACKBONE = 'vgg19'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "\n",
    "# size of patches\n",
    "patch_size = 128\n",
    "\n",
    "# Number of classes \n",
    "n_classes = 4\n",
    "# Specify the directory containing the images\n",
    "image_directory = \"../LargeImagesNotTested/\"\n",
    "\n",
    "# Define the result directory\n",
    "result_directory = f'segmentation_results_not_tested/{BACKBONE}/'\n",
    "os.makedirs(result_directory, exist_ok=True)\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = [file for file in os.listdir(image_directory) if file.endswith(\".jpg\")]\n",
    "\n",
    "# Load the model\n",
    "model = load_model(f'../Segmentation_Models/{BACKBONE}/CheckPoints/weights-improvement_{BACKBONE}.hdf5', compile=False)\n",
    "\n",
    "# Loop through each image file in the directory\n",
    "for image_file in image_files:\n",
    "    # Load the image\n",
    "    img = cv2.imread(os.path.join(image_directory, image_file))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input_img = preprocess_input(img)\n",
    "\n",
    "    # Predict using smooth blending\n",
    "    predictions_smooth = predict_img_with_smooth_windowing(\n",
    "        input_img,\n",
    "        window_size=patch_size,\n",
    "        subdivisions=2,\n",
    "        nb_classes=n_classes,\n",
    "        pred_func=(\n",
    "            lambda img_batch_subdiv: model.predict((img_batch_subdiv))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_prediction = np.argmax(predictions_smooth, axis=2).astype(np.uint8)\n",
    "    \n",
    "    # Save the final prediction\n",
    "    result_image_file = f'{result_directory}{os.path.splitext(image_file)[0]}_segmented_{BACKBONE}.tif'\n",
    "    print(result_image_file)\n",
    "    tiff.imwrite(result_image_file, final_prediction)\n",
    "    \n",
    "    # Display the original image and the prediction\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(121)\n",
    "    plt.title('Testing Image')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(122)\n",
    "    plt.title('Prediction with smooth blending')\n",
    "    plt.imshow(final_prediction, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8555a-fc89-49a7-9ac1-b9cf73b84c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
